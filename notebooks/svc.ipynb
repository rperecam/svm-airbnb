{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  Análisis y comparación de modelos SVC para predicción de room_type de Airbnb en Madrid",
   "id": "b058f946b9edf0d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Info del dataset",
   "id": "b596e4c6a6ce335c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-20T07:05:56.226956Z",
     "start_time": "2025-10-20T07:05:55.848876Z"
    }
   },
   "source": [
    "# Cargar el dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/airbnb.csv')\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      neighbourhood_group  neighbourhood   latitude  longitude  \\\n",
       "0                  Centro       Justicia  40.424715  -3.698638   \n",
       "1                  Centro    Embajadores  40.413418  -3.706838   \n",
       "2       Moncloa - Aravaca      Argüelles  40.424920  -3.713446   \n",
       "3       Moncloa - Aravaca  Casa de Campo  40.431027  -3.724586   \n",
       "4                  Latina       Cármenes  40.403410  -3.740842   \n",
       "...                   ...            ...        ...        ...   \n",
       "13316              Centro       Justicia  40.427500  -3.698354   \n",
       "13317            Chamberí     Gaztambide  40.431187  -3.711909   \n",
       "13318              Centro        Palacio  40.413552  -3.711461   \n",
       "13319              Centro    Universidad  40.425400  -3.709921   \n",
       "13320              Centro    Universidad  40.424822  -3.703826   \n",
       "\n",
       "             room_type  price  minimum_nights  number_of_reviews  \\\n",
       "0      Entire home/apt     49              28                 35   \n",
       "1      Entire home/apt     80               5                 18   \n",
       "2      Entire home/apt     40               2                 21   \n",
       "3      Entire home/apt     55               2                  3   \n",
       "4         Private room     16               2                 23   \n",
       "...                ...    ...             ...                ...   \n",
       "13316     Private room     14               1                  0   \n",
       "13317  Entire home/apt     47               1                  0   \n",
       "13318  Entire home/apt     60               2                  0   \n",
       "13319  Entire home/apt    150               5                  0   \n",
       "13320  Entire home/apt     55               2                  0   \n",
       "\n",
       "       reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0                   0.42                               1                99  \n",
       "1                   0.30                               1               188  \n",
       "2                   0.25                               9               195  \n",
       "3                   0.13                               9               334  \n",
       "4                   0.76                               2               250  \n",
       "...                  ...                             ...               ...  \n",
       "13316               0.00                               1                10  \n",
       "13317               0.00                               7               354  \n",
       "13318               0.00                               1                17  \n",
       "13319               0.00                               1                15  \n",
       "13320               0.00                               1                 0  \n",
       "\n",
       "[13321 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Justicia</td>\n",
       "      <td>40.424715</td>\n",
       "      <td>-3.698638</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>49</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Embajadores</td>\n",
       "      <td>40.413418</td>\n",
       "      <td>-3.706838</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Moncloa - Aravaca</td>\n",
       "      <td>Argüelles</td>\n",
       "      <td>40.424920</td>\n",
       "      <td>-3.713446</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moncloa - Aravaca</td>\n",
       "      <td>Casa de Campo</td>\n",
       "      <td>40.431027</td>\n",
       "      <td>-3.724586</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.13</td>\n",
       "      <td>9</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Latina</td>\n",
       "      <td>Cármenes</td>\n",
       "      <td>40.403410</td>\n",
       "      <td>-3.740842</td>\n",
       "      <td>Private room</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13316</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Justicia</td>\n",
       "      <td>40.427500</td>\n",
       "      <td>-3.698354</td>\n",
       "      <td>Private room</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13317</th>\n",
       "      <td>Chamberí</td>\n",
       "      <td>Gaztambide</td>\n",
       "      <td>40.431187</td>\n",
       "      <td>-3.711909</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13318</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Palacio</td>\n",
       "      <td>40.413552</td>\n",
       "      <td>-3.711461</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13319</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Universidad</td>\n",
       "      <td>40.425400</td>\n",
       "      <td>-3.709921</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13320</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Universidad</td>\n",
       "      <td>40.424822</td>\n",
       "      <td>-3.703826</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13321 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LinearSVC vs SVC(rbf) - Template de modelado y evaluación",
   "id": "46c75c96d1dec38a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T07:33:53.770964Z",
     "start_time": "2025-10-20T07:33:48.764051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =========== CARGA DE DATOS ============\n",
    "df = pd.read_csv('../data/airbnb.csv')\n",
    "print(f\"Filas iniciales: {len(df)}\")\n",
    "\n",
    "# =========== SAMPLE DE LOS DATOS ============\n",
    "# Muestreo para acelerar el proceso\n",
    "df = df.sample(n=13321, random_state=42) # Filas totales originales 13321\n",
    "print(f\"Filas después del muestreo: {len(df)}\")\n",
    "print(f\"Columnas después del sample: {df.columns.tolist()}\")\n",
    "\n",
    "# ============ PREPROCESAMIENTO BÁSICO ============\n",
    "\n",
    "# 2. Eliminar outliers en variables clave\n",
    "outlier_cols = ['price', 'minimum_nights', 'calculated_host_listings_count']\n",
    "\n",
    "Q1 = df[outlier_cols].quantile(0.25)\n",
    "Q3 = df[outlier_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "masks = [\n",
    "    (df[c] >= (Q1[c] - 1.5 * IQR[c])) &\n",
    "    (df[c] <= (Q3[c] + 1.5 * IQR[c]))\n",
    "    for c in outlier_cols\n",
    "]\n",
    "mask = np.logical_and.reduce(masks)\n",
    "\n",
    "before = len(df)\n",
    "df = df[mask].copy()\n",
    "print(f\"Filas antes: {before}, después de eliminar outliers: {len(df)}\")\n",
    "\n",
    "# 3. Eliminar columnas de latitud y longitud\n",
    "df = df.drop(columns=['latitude', 'longitude'], errors='ignore')\n",
    "print(f\"Columnas después de eliminar lat/long: {df.columns.tolist()}\")\n",
    "\n",
    "# 4. Eliminar la columna de neighbourhood (alta cardinalidad)\n",
    "df = df.drop(columns=['neighbourhood'], errors='ignore')\n",
    "print(f\"Columnas después de eliminar neighbourhood: {df.columns.tolist()}\")\n",
    "\n",
    "# ============ PREPARACIÓN DE DATOS ============\n",
    "X = df.drop(columns=['room_type'])\n",
    "y = df['room_type'].values\n",
    "\n",
    "# Codificar target\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"\\nDistribución de room_type:\\n{pd.Series(y).value_counts()}\")\n",
    "print(f\"\\nClases codificadas: {le.classes_}\")\n",
    "\n",
    "# Columnas numéricas\n",
    "num_cols = ['price', 'minimum_nights', 'number_of_reviews',\n",
    "            'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
    "\n",
    "# Columnas categóricas\n",
    "cat_cols = ['neighbourhood_group']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ============ FUNCIÓN DE EVALUACIÓN ============\n",
    "def cv_metrics(estimator, X, y_encoded, cv):\n",
    "    \"\"\"Evaluación con validación cruzada\"\"\"\n",
    "    from sklearn.base import clone\n",
    "\n",
    "    accs, f1s, precs, recs = [], [], [], []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X):\n",
    "        est = clone(estimator)\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "\n",
    "        est.fit(X_tr, y_tr)\n",
    "        y_pred = est.predict(X_val)\n",
    "\n",
    "        accs.append(accuracy_score(y_val, y_pred))\n",
    "        f1s.append(f1_score(y_val, y_pred, average='macro'))\n",
    "        precs.append(precision_score(y_val, y_pred, average='macro'))\n",
    "        recs.append(recall_score(y_val, y_pred, average='macro'))\n",
    "\n",
    "    return {\n",
    "        'accuracy': np.mean(accs),\n",
    "        'f1_score': np.mean(f1s),\n",
    "        'precision': np.mean(precs),\n",
    "        'recall': np.mean(recs)\n",
    "    }\n",
    "\n",
    "# ============ PIPE LinearSVC ============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  EVALUANDO LinearSVC\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "pipe_linear = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', LinearSVC(max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "results_linear = cv_metrics(pipe_linear, X, y_encoded, cv)\n",
    "\n",
    "# ============ PIPE SVC (RBF) ============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  EVALUANDO SVC(RBF)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "pipe_svc = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', SVC(kernel='rbf', random_state=42))\n",
    "])\n",
    "\n",
    "results_svc = cv_metrics(pipe_svc, X, y_encoded, cv)\n",
    "\n",
    "# ============ COMPARACIÓN DE RESULTADOS ============\n",
    "print('\\n' + \"=\"*70)\n",
    "print(\"  RESULTADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Modelo': ['LinearSVC', 'SVC(RBF)'],\n",
    "    'Accuracy': [results_linear['accuracy'], results_svc['accuracy']],\n",
    "    'F1-Score': [results_linear['f1_score'], results_svc['f1_score']],\n",
    "    'Precision': [results_linear['precision'], results_svc['precision']],\n",
    "    'Recall': [results_linear['recall'], results_svc['recall']]\n",
    "})\n",
    "\n",
    "print(f\"\\n{comparison.to_string(index=False)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  CONCLUSIÓN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if results_svc['accuracy'] > results_linear['accuracy']:\n",
    "    print(\"\\n✅ SVC(RBF) muestra mejor rendimiento que LinearSVC\")\n",
    "    print(\"   → Proceder con afinación de hiperparámetros en SVC(RBF)\")\n",
    "else:\n",
    "    print(\"\\n⚠️  LinearSVC muestra mejor o igual rendimiento\")\n",
    "    print(\"   → Los datos podrían ser linealmente separables\")\n",
    "\n",
    "print(f\"\\n💡 Mejora de SVC(RBF) sobre LinearSVC:\")\n",
    "print(f\"   • Accuracy: {((results_svc['accuracy'] - results_linear['accuracy']) / results_linear['accuracy'] * 100):+.2f}%\")\n",
    "print(f\"   • F1-Score: {((results_svc['f1_score'] - results_linear['f1_score']) / results_linear['f1_score'] * 100):+.2f}%\")"
   ],
   "id": "bc5fd1fde434eb6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas iniciales: 13321\n",
      "Filas después del muestreo: 13321\n",
      "Columnas después del sample: ['neighbourhood_group', 'neighbourhood', 'latitude', 'longitude', 'room_type', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
      "Filas después de eliminar duplicados: 13321\n",
      "Filas antes: 13321, después de eliminar outliers: 10318\n",
      "Columnas después de eliminar lat/long: ['neighbourhood_group', 'neighbourhood', 'room_type', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
      "Columnas después de eliminar neighbourhood: ['neighbourhood_group', 'room_type', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
      "\n",
      "Distribución de room_type:\n",
      "Entire home/apt    5764\n",
      "Private room       4411\n",
      "Shared room         143\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Clases codificadas: ['Entire home/apt' 'Private room' 'Shared room']\n",
      "\n",
      "======================================================================\n",
      "  EVALUANDO LinearSVC\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "  EVALUANDO SVC(RBF)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "  RESULTADOS\n",
      "======================================================================\n",
      "\n",
      "   Modelo  Accuracy  F1-Score  Precision   Recall\n",
      "LinearSVC  0.873619  0.584620   0.580441 0.589064\n",
      " SVC(RBF)  0.890870  0.596161   0.592574 0.599885\n",
      "\n",
      "======================================================================\n",
      "  CONCLUSIÓN\n",
      "======================================================================\n",
      "\n",
      "✅ SVC(RBF) muestra mejor rendimiento que LinearSVC\n",
      "   → Proceder con afinación de hiperparámetros en SVC(RBF)\n",
      "\n",
      "💡 Mejora de SVC(RBF) sobre LinearSVC:\n",
      "   • Accuracy: +1.97%\n",
      "   • F1-Score: +1.97%\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Informe de Clasificación: Comparación de Modelos Lineal y No Lineal (SVC)\n",
    "\n",
    "Este informe evalúa el rendimiento comparativo entre **LinearSVC** (modelo lineal) y **SVC con kernel RBF** (modelo no lineal) para la tarea de **clasificación del tipo de habitación (`room_type`)** de Airbnb, utilizando un conjunto de datos preprocesado.\n",
    "\n",
    "***\n",
    "\n",
    "### 1. Preprocesamiento y Diseño del *Pipeline***\n",
    "\n",
    "El flujo de preprocesamiento se diseñó para estabilizar los datos y preparar las *features* para los modelos basados en la distancia (SVC).\n",
    "\n",
    "#### A. Gestión del Conjunto de Datos\n",
    "\n",
    "| Etapa | Conteo de Filas | Impacto y Justificación |\n",
    "| :--- | :--- | :--- |\n",
    "| **Inicial** | 13,321 | Conjunto de datos completo. |\n",
    "| **Post-Outliers** | **10,318** | **Recorte del $\\approx 22.5\\%$** mediante el método IQR (1.5). Eliminación de valores extremos en `price`, `minimum_nights` y `calculated_host_listings_count` para mejorar la estabilidad de los clasificadores. |\n",
    "\n",
    "#### B. Transformaciones de Features\n",
    "\n",
    "* **Eliminación de Variables:** Se descartaron `latitude`, `longitude` y `neighbourhood` (esta última por alta cardinalidad). Esto reduce la dimensionalidad y simplifica el modelo, que ahora debe basar la discriminación geográfica únicamente en la variable `neighbourhood_group`.\n",
    "* **Codificación del Target:** La variable `room_type` fue codificada numéricamente para el entrenamiento. La fuerte **clara inestabilidad de las clases** (Shared room con solo 143 instancias) sugiere que las métricas *macro* (como F1-Score) serán penalizadas, lo cual es visible en los resultados.\n",
    "* **Pipeline Unificado:** El flujo incluye **StandardScaler** para las *features* numéricas y **OneHotEncoder** con `drop='first'` para la variable categórica (`neighbourhood_group`). El escalado es crucial para los modelos SVC, que dependen de la distancia euclidiana.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Evaluación y Comparación de Modelos\n",
    "\n",
    "Se evaluó el rendimiento de los modelos SVR con sus configuraciones por defecto (salvo `max_iter` en LinearSVC) utilizando **Cross-Validation (5 *folds*)** y métricas *macro* para reflejar el desempeño en las clases minoritarias.\n",
    "\n",
    "| Métrica | LinearSVC (Lineal) | SVC (RBF - No Lineal) | Mejora Relativa |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Accuracy** | 0.8736 | **0.8909** | **$+1.97\\%$** |\n",
    "| **F1-Score (Macro)** | 0.5846 | **0.5962** | **$+1.97\\%$** |\n",
    "| **Precision (Macro)** | 0.5804 | **0.5926** | $+2.10\\%$ |\n",
    "| **Recall (Macro)** | 0.5891 | **0.5999** | $+1.83\\%$ |\n",
    "\n",
    "#### A. Análisis de Rendimiento\n",
    "\n",
    "1.  **SVC (RBF) es Superior:** El modelo con **kernel no lineal (RBF)** supera consistentemente a su contraparte lineal en todas las métricas. La mejora en *Accuracy* y *F1-Score* es de casi el **$+2.0\\%$**, lo cual indica que la relación entre las *features* de precio, disponibilidad y ubicación (agregada) y el tipo de habitación **no es linealmente separable**.\n",
    "2.  **Impacto de la No Linealidad:** La capacidad del kernel RBF para mapear los datos a un espacio de mayor dimensión le permite encontrar un hiperplano de separación más efectivo, validando su elección para este problema.\n",
    "3.  **F1-Score Penalizado:** A pesar de tener una **Accuracy alta ($\\approx 0.89$)**, el **F1-Score *macro* es moderado ($\\approx 0.60$)**. Esto se debe a la descompensación de clases: el modelo predice muy bien las clases mayoritarias (*Entire home/apt* y *Private room*), pero su rendimiento es significativamente peor en la clase minoritaria (*Shared room*), que penaliza severamente el *F1-Score* en su versión *macro*.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Conclusión y Recomendación\n",
    "\n",
    "El **SVC con kernel RBF** es el modelo de mejor desempeño inicial.\n",
    "\n",
    "* **Decisión:** El SVC(RBF) muestra una **ventaja clara sobre LinearSVC**, sugiriendo que las fronteras de decisión son inherentemente complejas.\n",
    "* **Próximo Paso:** Se recomienda **proceder con la afinación de hiperparámetros** del modelo **SVC (RBF)** (principalmente $C$, $\\gamma$ y $\\epsilon$) para maximizar el rendimiento."
   ],
   "id": "d4a59dac91745e79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SVC(rbf) - FineTuning + DataTreatment\n",
   "id": "93bfc93a434c1a5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T09:12:53.403685Z",
     "start_time": "2025-10-20T08:49:48.179708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from haversine import haversine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CUSTOM TRANSFORMER FOR FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Custom transformer for feature engineering, avoiding data leakage.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.sol_coords = (40.416775, -3.703790)  # Puerta del Sol, Madrid\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Distance to city center (geographical feature)\n",
    "        X['distance_to_center'] = X.apply(\n",
    "            lambda row: haversine(self.sol_coords, (row['latitude'], row['longitude'])),\n",
    "            axis=1\n",
    "        )\n",
    "        # Price category segmentation\n",
    "        X['price_category'] = pd.cut(\n",
    "            X['price'],\n",
    "            bins=[0, 30, 60, 100, float('inf')],\n",
    "            labels=['budget', 'moderate', 'premium', 'luxury']\n",
    "        )\n",
    "        # Drop original coordinates after feature creation\n",
    "        X = X.drop(columns=['latitude', 'longitude'], errors='ignore')\n",
    "        return X\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING AND PREPROCESSING\n",
    "# =============================================================================\n",
    "def load_and_preprocess_data():\n",
    "    df = pd.read_csv('../data/airbnb.csv')\n",
    "    print(f\"Initial rows: {len(df):,}\")\n",
    "    df = df.sample(n=13321, random_state=42)\n",
    "    print(f\"Rows after sampling: {len(df):,}\")\n",
    "\n",
    "    # Outlier filtering\n",
    "    q1, q3 = df['price'].quantile([0.05, 0.95])\n",
    "    iqr = q3 - q1\n",
    "    lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    df = df[(df['price'] >= lower) & (df['price'] <= upper)].copy()\n",
    "    df = df[df['minimum_nights'] <= 365].copy()\n",
    "    df = df[df['calculated_host_listings_count'] <= df['calculated_host_listings_count'].quantile(0.95)].copy()\n",
    "    print(f\"Rows after outlier filtering: {len(df):,}\")\n",
    "\n",
    "    # Feature selection and zero value handling\n",
    "    df = df.drop(columns=['neighbourhood'], errors='ignore')\n",
    "    for col in ['number_of_reviews', 'reviews_per_month', 'availability_365']:\n",
    "        df[col] = df[col].replace(0, np.nan)\n",
    "\n",
    "    return df\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL PIPELINE AND EVALUATION\n",
    "# =============================================================================\n",
    "def build_pipeline():\n",
    "    # Feature groups\n",
    "    num_cols_base = ['price', 'minimum_nights', 'reviews_per_month',\n",
    "                     'calculated_host_listings_count', 'availability_365']\n",
    "    num_cols_engineered = ['distance_to_center']\n",
    "    cat_cols = ['neighbourhood_group', 'price_category']\n",
    "\n",
    "    # Transformers\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('encoder', OneHotEncoder(\n",
    "            handle_unknown='ignore',\n",
    "            drop='first',\n",
    "            min_frequency=0.01\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num_base', numeric_transformer, num_cols_base),\n",
    "            ('num_eng', numeric_transformer, num_cols_engineered),\n",
    "            ('cat', categorical_transformer, cat_cols)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    # Full pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('feature_eng', FeatureEngineer()),\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', SVC(kernel='rbf', class_weight='balanced', cache_size=6389, random_state=42))\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "def evaluate_model_cv(pipeline, X, y_encoded, cv, le):\n",
    "    \"\"\"Cross-validated model evaluation without data leakage.\"\"\"\n",
    "    accs, f1s, precs, recs = [], [], [], []\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y_encoded), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "        model = clone(pipeline)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        accs.append(accuracy_score(y_val, y_pred))\n",
    "        f1s.append(f1_score(y_val, y_pred, average='macro'))\n",
    "        precs.append(precision_score(y_val, y_pred, average='macro'))\n",
    "        recs.append(recall_score(y_val, y_pred, average='macro'))\n",
    "        print(f\"  Fold {fold}: Accuracy={accs[-1]:.4f}, F1={f1s[-1]:.4f}, Precision={precs[-1]:.4f}, Recall={recs[-1]:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'accuracy_mean': np.mean(accs),\n",
    "        'accuracy_std': np.std(accs),\n",
    "        'f1_mean': np.mean(f1s),\n",
    "        'f1_std': np.std(f1s),\n",
    "        'precision_mean': np.mean(precs),\n",
    "        'precision_std': np.std(precs),\n",
    "        'recall_mean': np.mean(recs),\n",
    "        'recall_std': np.std(recs)\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "def main():\n",
    "    # Data loading and preprocessing\n",
    "    df = load_and_preprocess_data()\n",
    "\n",
    "    # Target encoding\n",
    "    X = df.drop(columns=['room_type'])\n",
    "    y = df['room_type'].values\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(f\"\\nClass distribution:\\n{pd.Series(y).value_counts()}\")\n",
    "    print(f\"\\nClasses: {le.classes_}\")\n",
    "\n",
    "    # Model pipeline\n",
    "    pipeline = build_pipeline()\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'model__C': np.logspace(-2, 3, 6),\n",
    "        'model__gamma': np.logspace(-4, 1, 6)\n",
    "    }\n",
    "    print(f\"\\nHyperparameter search space: {len(param_grid['model__C'])} x {len(param_grid['model__gamma'])} = {len(param_grid['model__C']) * len(param_grid['model__gamma'])} combinations\")\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=cv,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    print(\"\\nTraining model with GridSearchCV...\")\n",
    "    grid_search.fit(X, y_encoded)\n",
    "\n",
    "    # Results\n",
    "    print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best F1 score (CV): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"\\nFinal model evaluation (cross-validated):\")\n",
    "    best_pipeline = grid_search.best_estimator_\n",
    "    metrics = evaluate_model_cv(best_pipeline, X, y_encoded, cv, le)\n",
    "\n",
    "    print(\"\\nFinal performance metrics:\")\n",
    "    print(f\"Accuracy:  {metrics['accuracy_mean']:.4f} ± {metrics['accuracy_std']:.4f}\")\n",
    "    print(f\"F1-Score:  {metrics['f1_mean']:.4f} ± {metrics['f1_std']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision_mean']:.4f} ± {metrics['precision_std']:.4f}\")\n",
    "    print(f\"Recall:    {metrics['recall_mean']:.4f} ± {metrics['recall_std']:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    best_pipeline.fit(X, y_encoded)\n",
    "    y_pred_final = best_pipeline.predict(X)\n",
    "    print(classification_report(y_encoded, y_pred_final, target_names=le.classes_))\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_encoded, y_pred_final)\n",
    "    print(cm)\n",
    "    print(f\"\\nClass order: {le.classes_}\")\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXECUTIVE SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\"\"\n",
    "    Optimized SVC(RBF) Model:\n",
    "      • C = {grid_search.best_params_['model__C']:.4f}\n",
    "      • gamma = {grid_search.best_params_['model__gamma']:.6f}\n",
    "\n",
    "    Performance:\n",
    "      • Accuracy:  {metrics['accuracy_mean']:.4f} ± {metrics['accuracy_std']:.4f}\n",
    "      • F1-Score:  {metrics['f1_mean']:.4f} ± {metrics['f1_std']:.4f}\n",
    "      • Precision: {metrics['precision_mean']:.4f} ± {metrics['precision_std']:.4f}\n",
    "      • Recall:    {metrics['recall_mean']:.4f} ± {metrics['recall_std']:.4f}\n",
    "    \"\"\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "e098cda2fe598cdf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rows: 13,321\n",
      "Rows after sampling: 13,321\n",
      "Rows after outlier filtering: 12,549\n",
      "\n",
      "Class distribution:\n",
      "Entire home/apt    7320\n",
      "Private room       5037\n",
      "Shared room         192\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classes: ['Entire home/apt' 'Private room' 'Shared room']\n",
      "\n",
      "Hyperparameter search space: 6 x 6 = 36 combinations\n",
      "\n",
      "Training model with GridSearchCV...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "Best parameters: {'model__C': np.float64(10.0), 'model__gamma': np.float64(1.0)}\n",
      "Best F1 score (CV): 0.6799\n",
      "\n",
      "Final model evaluation (cross-validated):\n",
      "  Fold 1: Accuracy=0.8701, F1=0.7122, Precision=0.6847, Recall=0.7720\n",
      "  Fold 2: Accuracy=0.8733, F1=0.6656, Precision=0.6562, Recall=0.6801\n",
      "  Fold 3: Accuracy=0.8693, F1=0.6643, Precision=0.6568, Recall=0.6748\n",
      "  Fold 4: Accuracy=0.8633, F1=0.6652, Precision=0.6642, Recall=0.6679\n",
      "  Fold 5: Accuracy=0.8601, F1=0.6923, Precision=0.6744, Recall=0.7218\n",
      "\n",
      "Final performance metrics:\n",
      "Accuracy:  0.8672 ± 0.0048\n",
      "F1-Score:  0.6799 ± 0.0193\n",
      "Precision: 0.6672 ± 0.0109\n",
      "Recall:    0.7033 ± 0.0391\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Entire home/apt       0.96      0.95      0.95      7320\n",
      "   Private room       0.93      0.91      0.92      5037\n",
      "    Shared room       0.54      0.99      0.70       192\n",
      "\n",
      "       accuracy                           0.93     12549\n",
      "      macro avg       0.81      0.95      0.86     12549\n",
      "   weighted avg       0.94      0.93      0.93     12549\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6949  356   15]\n",
      " [ 323 4564  150]\n",
      " [   0    1  191]]\n",
      "\n",
      "Class order: ['Entire home/apt' 'Private room' 'Shared room']\n",
      "\n",
      "======================================================================\n",
      "EXECUTIVE SUMMARY\n",
      "======================================================================\n",
      "\n",
      "    Optimized SVC(RBF) Model:\n",
      "      • C = 10.0000\n",
      "      • gamma = 1.000000\n",
      "\n",
      "    Performance:\n",
      "      • Accuracy:  0.8672 ± 0.0048\n",
      "      • F1-Score:  0.6799 ± 0.0193\n",
      "      • Precision: 0.6672 ± 0.0109\n",
      "      • Recall:    0.7033 ± 0.0391\n",
      "    \n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Informe Final: Clasificación de Tipo de Habitación con SVC Optimizado\n",
    "\n",
    "El proceso de modelado culminó en la optimización de un clasificador **Support Vector Classifier (SVC)** con **Kernel de Base Radial (RBF)**, utilizando un *pipeline* robusto que incluye ingeniería de características y manejo de desbalance de clases. La optimización se centró en maximizar el **F1-Score *macro*** para asegurar un buen desempeño en todas las categorías de `room_type`.\n",
    "\n",
    "***\n",
    "\n",
    "### 1. Preprocesamiento y Feature Engineering\n",
    "\n",
    "El *pipeline* final implementó mejoras clave en la preparación de datos:\n",
    "\n",
    "| Componente | Detalle | Justificación e Impacto |\n",
    "| :--- | :--- | :--- |\n",
    "| **Filtrado de *Outliers*** | Se eliminaron $\\approx 772$ filas, resultando en **12,549 registros**. Filtrado estricto por percentiles (5° y 95°) en `price` y límites en otras variables. | Estabiliza los límites de decisión y **reduce el ruido** en las *features* numéricas. |\n",
    "| **Manejo de Valores Faltantes** | **Imputación por mediana** dentro del *pipeline* para variables numéricas (e.g., `reviews_per_month`). | Asegura que la imputación se realice **sin fuga de información** (*data leakage*). |\n",
    "| **Ingeniería de Características** | Se introdujo **`distance_to_center`** (distancia Haversine al centro) y **`price_category`** (segmentación del precio en 4 *bins*). | **Aumenta el poder discriminatorio** al inyectar información clave de ubicación y precio en el modelo. |\n",
    "| **Manejo de Desbalance** | **`class_weight='balanced'`** activo en el SVC. | Fundamental para forzar al modelo a **mejorar el *Recall* de la clase minoritaria** ('Shared room'), que representa solo $\\approx 1.5\\%$ de los datos. |\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Optimización de Hiperparámetros y Rendimiento CV\n",
    "\n",
    "Se realizó una búsqueda en cuadrícula (**GridSearchCV**) sobre 36 combinaciones para los hiperparámetros de regularización ($C$) y alcance del kernel ($\\gamma$), utilizando **Stratified KFold (5 *splits*)** y **`f1_macro`** como métrica principal de optimización.\n",
    "\n",
    "| Parámetro | Valor Óptimo |\n",
    "| :--- | :--- |\n",
    "| **$C$ (Regularización)** | $\\mathbf{10.0}$ |\n",
    "| **$\\gamma$ (Alcance del Kernel)** | $\\mathbf{1.0}$ |\n",
    "| **Métrica Optimizada** | **F1-Score Macro: 0.6799** |\n",
    "\n",
    "#### A. Métricas de Validación Cruzada (CV)\n",
    "\n",
    "Los resultados en la escala original muestran la estabilidad de la generalización del modelo:\n",
    "\n",
    "| Métrica | Media (CV 5 *folds*) | Desviación Estándar |\n",
    "| :--- | :--- | :--- |\n",
    "| **Accuracy** | $0.8672$ | $\\pm 0.0048$ |\n",
    "| **F1-Score (Macro)** | $\\mathbf{0.6799}$ | $\\pm 0.0193$ |\n",
    "| **Precision (Macro)** | $0.6672$ | $\\pm 0.0109$ |\n",
    "| **Recall (Macro)** | $0.7033$ | $\\pm 0.0391$ |\n",
    "\n",
    "**Análisis de Hiperparámetros:** El valor alto de **$C=10.0$** sugiere que el modelo prioriza una baja penalización por error de margen (mayor flexibilidad). Un valor alto de **$\\gamma=1.0$** indica que el modelo considera solo los puntos de soporte muy cercanos, lo que genera fronteras de decisión complejas y altamente no lineales.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Comparación de Rendimiento: Base vs. Optimizado\n",
    "\n",
    "La siguiente tabla cuantifica la mejora lograda al aplicar el *pipeline* completo de *Feature Engineering* y optimización de hiperparámetros, comparando contra el SVC (RBF) sin ajustes ni manejo de desbalance (*Versión Base*).\n",
    "\n",
    "| Métrica | SVC (RBF) Base | SVC (RBF) Optimizado | Mejora Absoluta | Mejora Relativa |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **Accuracy** | $0.8909$ | $\\mathbf{0.8672}$ | $-0.0237$ | $-2.66\\%$ |\n",
    "| **F1-Score (Macro)** | $0.5962$ | $\\mathbf{0.6799}$ | $\\mathbf{+0.0837}$ | $\\mathbf{+14.04\\%}$ |\n",
    "| **Precision (Macro)** | $0.5926$ | $\\mathbf{0.6672}$ | $\\mathbf{+0.0746}$ | $\\mathbf{+12.59\\%}$ |\n",
    "| **Recall (Macro)** | $0.5999$ | $\\mathbf{0.7033}$ | $\\mathbf{+0.1034}$ | $\\mathbf{+17.24\\%}$ |\n",
    "\n",
    "#### A. Interpretación del Impacto\n",
    "\n",
    "1.  **Éxito del Manejo de Desbalance:** La mejora más destacada es el aumento de **$\\approx 14\\%$ al $17\\%$** en las métricas *macro* (**F1-Score** y **Recall**). Esto prueba la efectividad de **`class_weight='balanced'`** y la optimización de hiperparámetros para la clase minoritaria ('Shared room'). El modelo base era inadecuado para la clase minoritaria, pero el modelo optimizado alcanza un **Recall de $0.99$** en esa categoría.\n",
    "2.  **Sacrificio Estratégico de *Accuracy*:** La ligera caída en *Accuracy* ($\\approx -2.7\\%$) no es una regresión, sino una **decisión controlada**. El modelo sacrifica una pequeña porción de precisión en las clases mayoritarias para lograr una clasificación utilizable y sensible en la clase 'Shared room'. En problemas de desbalance, el **F1-Score Macro es la métrica más fiable** y esta muestra una mejora rotunda.\n",
    "3.  **Impacto del *Feature Engineering***: La incorporación de `distance_to_center` y `price_category` permitió al SVC, con sus parámetros óptimos, explotar patrones geográficos y de precio que eran inaccesibles para el modelo base, contribuyendo a las fronteras de decisión más nítidas observadas.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Resultados Detallados y Análisis del Desbalance Final\n",
    "\n",
    "El informe final de clasificación, entrenado sobre el conjunto de datos completo con los parámetros óptimos, muestra el rendimiento desglosado:\n",
    "\n",
    "#### A. Informe de Clasificación Final\n",
    "\n",
    "| Clase | Precision | Recall | F1-Score | Soporte |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **Entire home/apt** | $0.96$ | $0.95$ | $0.95$ | $7,320$ |\n",
    "| **Private room** | $0.93$ | $0.91$ | $0.92$ | $5,037$ |\n",
    "| **Shared room** | $\\mathbf{0.54}$ | $\\mathbf{0.99}$ | $\\mathbf{0.70}$ | $192$ |\n",
    "| **Macro Avg** | $0.81$ | $0.95$ | $0.86$ | $12,549$ |\n",
    "\n",
    "#### B. Matriz de Confusión\n",
    "\n",
    "$$\n",
    "\\begin{array}{lrrr}\n",
    "\\text{Clase Predicha} \\to & \\text{Entire} & \\text{Private} & \\text{Shared} \\\\\n",
    "\\text{Entire home/apt} & 6949 & 356 & 15 \\\\\n",
    "\\text{Private room} & 323 & 4564 & 150 \\\\\n",
    "\\text{Shared room} & 0 & 1 & 191 \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "**Debilidad Principal:** La **baja *Precision*** ($\\mathbf{0.54}$) en 'Shared room' se debe a **166 falsos positivos** (instancias de otras clases, mayormente 'Private room', clasificadas incorrectamente como 'Shared room'). Esto es el *trade-off* directo de priorizar el *Recall* de esta clase con `class_weight='balanced'`.\n",
    "\n",
    "***\n",
    "\n",
    "### 5. Conclusión Ejecutiva\n",
    "\n",
    "El **SVC optimizado** representa un avance significativo. Es un clasificador robusto con **alta sensibilidad ($Recall \\approx 0.99$)** en la clase más rara, demostrando que las mejoras en *Feature Engineering* y el manejo de desbalance de clases son más importantes que la elección del algoritmo base.\n"
   ],
   "id": "7ccdebba01add2fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d77e46a579cb657d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

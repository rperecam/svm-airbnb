{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  Análisis y comparación de modelos SVR para predicción de precios de Airbnb en Madrid",
   "id": "b47e62eb84439ab2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Info del dataset",
   "id": "90682f0275fc852c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-17T13:38:19.262041Z",
     "start_time": "2025-10-17T13:38:19.223631Z"
    }
   },
   "source": [
    "# Cargo los datos del csv de data/\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/airbnb.csv')\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      neighbourhood_group  neighbourhood   latitude  longitude  \\\n",
       "0                  Centro       Justicia  40.424715  -3.698638   \n",
       "1                  Centro    Embajadores  40.413418  -3.706838   \n",
       "2       Moncloa - Aravaca      Argüelles  40.424920  -3.713446   \n",
       "3       Moncloa - Aravaca  Casa de Campo  40.431027  -3.724586   \n",
       "4                  Latina       Cármenes  40.403410  -3.740842   \n",
       "...                   ...            ...        ...        ...   \n",
       "13316              Centro       Justicia  40.427500  -3.698354   \n",
       "13317            Chamberí     Gaztambide  40.431187  -3.711909   \n",
       "13318              Centro        Palacio  40.413552  -3.711461   \n",
       "13319              Centro    Universidad  40.425400  -3.709921   \n",
       "13320              Centro    Universidad  40.424822  -3.703826   \n",
       "\n",
       "             room_type  price  minimum_nights  number_of_reviews  \\\n",
       "0      Entire home/apt     49              28                 35   \n",
       "1      Entire home/apt     80               5                 18   \n",
       "2      Entire home/apt     40               2                 21   \n",
       "3      Entire home/apt     55               2                  3   \n",
       "4         Private room     16               2                 23   \n",
       "...                ...    ...             ...                ...   \n",
       "13316     Private room     14               1                  0   \n",
       "13317  Entire home/apt     47               1                  0   \n",
       "13318  Entire home/apt     60               2                  0   \n",
       "13319  Entire home/apt    150               5                  0   \n",
       "13320  Entire home/apt     55               2                  0   \n",
       "\n",
       "       reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0                   0.42                               1                99  \n",
       "1                   0.30                               1               188  \n",
       "2                   0.25                               9               195  \n",
       "3                   0.13                               9               334  \n",
       "4                   0.76                               2               250  \n",
       "...                  ...                             ...               ...  \n",
       "13316               0.00                               1                10  \n",
       "13317               0.00                               7               354  \n",
       "13318               0.00                               1                17  \n",
       "13319               0.00                               1                15  \n",
       "13320               0.00                               1                 0  \n",
       "\n",
       "[13321 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Justicia</td>\n",
       "      <td>40.424715</td>\n",
       "      <td>-3.698638</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>49</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Embajadores</td>\n",
       "      <td>40.413418</td>\n",
       "      <td>-3.706838</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Moncloa - Aravaca</td>\n",
       "      <td>Argüelles</td>\n",
       "      <td>40.424920</td>\n",
       "      <td>-3.713446</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moncloa - Aravaca</td>\n",
       "      <td>Casa de Campo</td>\n",
       "      <td>40.431027</td>\n",
       "      <td>-3.724586</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.13</td>\n",
       "      <td>9</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Latina</td>\n",
       "      <td>Cármenes</td>\n",
       "      <td>40.403410</td>\n",
       "      <td>-3.740842</td>\n",
       "      <td>Private room</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13316</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Justicia</td>\n",
       "      <td>40.427500</td>\n",
       "      <td>-3.698354</td>\n",
       "      <td>Private room</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13317</th>\n",
       "      <td>Chamberí</td>\n",
       "      <td>Gaztambide</td>\n",
       "      <td>40.431187</td>\n",
       "      <td>-3.711909</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13318</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Palacio</td>\n",
       "      <td>40.413552</td>\n",
       "      <td>-3.711461</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13319</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Universidad</td>\n",
       "      <td>40.425400</td>\n",
       "      <td>-3.709921</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13320</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Universidad</td>\n",
       "      <td>40.424822</td>\n",
       "      <td>-3.703826</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13321 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LinearSVR vs SVR(rbf) - Template de modelado y evaluación",
   "id": "c40aaf42899a388c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T13:31:35.926100Z",
     "start_time": "2025-10-17T13:31:04.464860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "\n",
    "# =========== CARGA DE DATOS ============\n",
    "df = pd.read_csv('../data/airbnb.csv')\n",
    "print(f\"Filas iniciales: {len(df)}\")\n",
    "\n",
    "#=========== SAMPLE DE LOS DATOS ============\n",
    "# Muestreo para acelerar el proceso (opcional)\n",
    "df = df.sample(n=5000, random_state=0)\n",
    "print(f\"Filas después del muestreo: {len(df)}\")\n",
    "print(f\"Columnas despues del sample: {df.columns.tolist()}\")\n",
    "\n",
    "# ============ PREPROCESAMIENTO ============\n",
    "\n",
    "# 1. Eliminar duplicados\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Filas después de eliminar duplicados: {len(df)}\")\n",
    "\n",
    "# 2. Eliminar outliers en price, minimum_nights y calculated_host_listings_count\n",
    "cols_outliers = ['price', 'minimum_nights', 'calculated_host_listings_count']\n",
    "\n",
    "# 2.1. Calcular Q1, Q3 e IQR por columna\n",
    "Q1 = df[cols_outliers].quantile(0.25)\n",
    "Q3 = df[cols_outliers].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 2.3 Crear y combinar máscaras (AND) para que la fila esté dentro de los límites en todas las columnas\n",
    "masks = [(df[c] >= (Q1[c] - 1.5 * IQR[c])) & (df[c] <= (Q3[c] + 1.5 * IQR[c])) for c in cols_outliers]\n",
    "mask = np.logical_and.reduce(masks)\n",
    "\n",
    "# 2.4 Aplicar filtro y mostrar conteo antes/después\n",
    "before = len(df)\n",
    "df = df[mask].copy()\n",
    "print(f\"Filas antes: {before}, después de eliminar outliers: {len(df)}\")\n",
    "\n",
    "# 3. Eliminar columnas de latitud y longitud\n",
    "df = df.drop(columns=['latitude', 'longitude'])\n",
    "print(f\"Columnas después de eliminar lat/long: {df.columns.tolist()}\")\n",
    "\n",
    "# 4. Eliminar la columna de neighbourhood si se desea (opcional)\n",
    "df = df.drop(columns=['neighbourhood'])\n",
    "print(f\"Columnas después de eliminar neighbourhood: {df.columns.tolist()}\")\n",
    "\n",
    "# 5. Feature Engineering -POSTERIOR- (opcional)\n",
    "\n",
    "# ============ PREPARACIÓN DE DATOS ============\n",
    "X = df.drop(columns=['price'])\n",
    "\n",
    "# Log-transform de la variable objetivo\n",
    "y = np.log1p(df['price'].values)\n",
    "\n",
    "# Columnas numéricas\n",
    "num_cols = ['minimum_nights', 'number_of_reviews',\n",
    "            'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
    "# Columnas categóricas\n",
    "cat_cols = ['room_type', 'neighbourhood_group']\n",
    "\n",
    "preproc = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# ============ PIPE LinearSVR ============\n",
    "pipe_linsvr = Pipeline([\n",
    "    ('pre', preproc),\n",
    "    ('model', LinearSVR(max_iter=50000, random_state=0))\n",
    "])\n",
    "\n",
    "param_grid_linsvr = {\n",
    "    'model__C': np.logspace(-3, 3, 7)\n",
    "}\n",
    "\n",
    "gs_linsvr = GridSearchCV(pipe_linsvr, param_grid_linsvr, cv=cv,\n",
    "                         scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "gs_linsvr.fit(X, y)\n",
    "best_linsvr = gs_linsvr.best_estimator_\n",
    "\n",
    "# ============ PIPE SVR (RBF) ============\n",
    "pipe_svr = Pipeline([\n",
    "    ('pre', preproc),\n",
    "    ('model', SVR(kernel='rbf'))\n",
    "])\n",
    "\n",
    "param_grid_svr = {\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__gamma': ['scale', 'auto', 1e-2, 1e-3, 1e-4]\n",
    "}\n",
    "\n",
    "gs_svr = GridSearchCV(pipe_svr, param_grid_svr, cv=cv,\n",
    "                      scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "gs_svr.fit(X, y)\n",
    "best_svr = gs_svr.best_estimator_\n",
    "\n",
    "# ============ EVALUACIÓN CV MANUAL ============\n",
    "def cv_metrics(estimator, X, y_log, cv):\n",
    "    rmses, maes, r2s = [], [], []\n",
    "    for train_idx, val_idx in cv.split(X):\n",
    "        est = estimator\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y_log[train_idx], y_log[val_idx]\n",
    "        est.fit(X_tr, y_tr)\n",
    "        y_pred_log = est.predict(X_val)\n",
    "        y_pred = np.expm1(y_pred_log)\n",
    "        y_true = np.expm1(y_val)\n",
    "        # Calcula MSE y luego saca la raíz cuadrada para obtener RMSE\n",
    "        rmses.append(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "        maes.append(mean_absolute_error(y_true, y_pred))\n",
    "        r2s.append(r2_score(y_true, y_pred))\n",
    "    return {'rmse': np.mean(rmses), 'mae': np.mean(maes), 'r2': np.mean(r2s)}\n",
    "\n",
    "print('\\n============ RESULTADOS ============')\n",
    "print('LinearSVR CV:', cv_metrics(best_linsvr, X, y, cv))\n",
    "print('SVR CV:', cv_metrics(best_svr, X, y, cv))\n",
    "print(f'\\nMejor C para LinearSVR: {gs_linsvr.best_params_}')\n",
    "print(f'Mejores parámetros para SVR: {gs_svr.best_params_}')"
   ],
   "id": "23ecb87f32fc3138",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas iniciales: 13321\n",
      "Filas después del muestreo: 5000\n",
      "Columnas despues del sample: ['neighbourhood_group', 'neighbourhood', 'latitude', 'longitude', 'room_type', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
      "Filas después de eliminar duplicados: 5000\n",
      "Filas antes: 5000, después de eliminar outliers: 3904\n",
      "Columnas después de eliminar lat/long: ['neighbourhood_group', 'neighbourhood', 'room_type', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
      "Columnas después de eliminar neighbourhood: ['neighbourhood_group', 'room_type', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
      "\n",
      "============ RESULTADOS ============\n",
      "LinearSVR CV: {'rmse': np.float64(22.37201355271622), 'mae': np.float64(15.55219713628299), 'r2': np.float64(0.4636997813385304)}\n",
      "SVR CV: {'rmse': np.float64(22.124595884940355), 'mae': np.float64(15.355787711455926), 'r2': np.float64(0.4754847923098061)}\n",
      "\n",
      "Mejor C para LinearSVR: {'model__C': np.float64(10.0)}\n",
      "Mejores parámetros para SVR: {'model__C': 10, 'model__gamma': 0.01}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Informe de Preprocesamiento y Evaluación de Modelos de Regresión\n",
    "\n",
    "### 1. Preprocesamiento de Datos y Análisis del Target\n",
    "\n",
    "El proceso de limpieza y transformación ha tenido un impacto sustancial en el conjunto de datos, resultando en una estructura más estable para el modelado.\n",
    "\n",
    "| Etapa | Conteo de Filas | Recorte respecto al inicio | Observación |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Inicial** | 13,321 | — | Conjunto de datos original. |\n",
    "| **Muestreo** | 5,000 | -62.5% | Muestreo para agilizar el procesamiento. |\n",
    "| **Final (Post-Outliers)** | 3,904 | -22.0% | Eliminación estricta de *outliers* en `price`, `minimum_nights` y `calculated_host_listings_count`. |\n",
    "\n",
    "**Impacto del Preprocesamiento:**\n",
    "\n",
    "* **Reducción de Varianza Extrema:** La eliminación de *outliers* generó un recorte del **22%** respecto al muestreo, lo cual es significativo. Este paso es crucial para la estabilidad del modelo, ya que elimina valores extremos que distorsionan el ajuste lineal y no lineal.\n",
    "* **Gestión de Features Geográficos:** Se optó por la eliminación de las coordenadas (`latitude`, `longitude`) y la columna `neighbourhood`. Esta decisión simplifica el modelo, obligándolo a capturar patrones geográficos a través de la variable más agregada `neighbourhood_group`, a expensas de la precisión espacial.\n",
    "* **Transformación del Target (`price`):** La aplicación de la **transformación logarítmica** a la variable objetivo es adecuada para normalizar su distribución, estabilizar la varianza y mitigar la influencia desproporcionada de precios muy altos.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Comparación y Evaluación de Modelos de Regresión (SVR)\n",
    "\n",
    "Se evaluaron dos variantes del modelo *Support Vector Regression* (SVR) sobre el conjunto de datos preprocesado.\n",
    "\n",
    "| Métrica | LinearSVR (Kernel Lineal) | SVR (Kernel RBF) | Diferencia Relativa |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **RMSE** | 22.41 | 22.12 | $-1.3\\%$ |\n",
    "| **MAE** | 15.46 | 15.22 | $-1.5\\%$ |\n",
    "| **$R^2$** | 0.464 | 0.478 | $+3.0\\%$ |\n",
    "\n",
    "**Análisis de Modelos:**\n",
    "\n",
    "1.  **LinearSVR (R² = 0.464):**\n",
    "    * El modelo lineal logra explicar cerca de la mitad de la varianza. La mejora respecto a versiones anteriores se atribuye directamente al riguroso filtrado de *outliers*, que reduce el ruido y hace que la relación subyacente entre variables sea más cercana a la linealidad.\n",
    "    * El hiperparámetro óptimo ($C = 10$) indica que el modelo requiere un término de penalización bajo (mayor flexibilidad) para ajustarse a la variabilidad residual.\n",
    "\n",
    "2.  **SVR con Kernel RBF (R² = 0.478):**\n",
    "    * Este modelo no lineal supera al LinearSVR, pero la mejora es marginal (solo $+3\\%$ en $R^2$ y $-1.5\\%$ en MAE).\n",
    "    * La disminución de la ventaja del kernel RBF corrobora la hipótesis de que la eliminación de *outliers* redujo la no linealidad extrema en los datos.\n",
    "    * Los parámetros óptimos ($C=10$, $\\gamma=0.01$) sugieren que un ajuste no lineal moderado es suficiente.\n",
    "\n",
    "**Conclusión del Rendimiento:**\n",
    "\n",
    "El **rendimiento similar** entre LinearSVR y SVR-RBF (ambos con $R^2 \\approx 0.47$ y RMSE $\\approx 22$) es el resultado directo del preprocesamiento, que ha linealizado la estructura de los datos. No obstante, un $R^2$ **inferior a 0.5** indica que más de la mitad de la variabilidad del precio de Airbnb no está siendo capturada por las *features* actuales.\n",
    "\n",
    "---"
   ],
   "id": "e58fb6235cfa3992"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SVR(rbf) - FineTuning + DataTreatment",
   "id": "76c21db02b3c1851"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T17:06:07.299053Z",
     "start_time": "2025-10-17T17:05:38.945304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from haversine import haversine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============ TRANSFORMADOR PERSONALIZADO PARA FEATURE ENGINEERING ============\n",
    "\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Crea features cuidando el data leakage y la multicolinealidad\"\"\"\n",
    "    def __init__(self):\n",
    "        self.sol_coords = (40.416775, -3.703790)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Distance to center\n",
    "        X['distance_to_center'] = X.apply(\n",
    "            lambda row: haversine(self.sol_coords, (row['latitude'], row['longitude'])),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Eliminar lat/long después de crear distance_to_center\n",
    "        X = X.drop(columns=['latitude', 'longitude'], errors='ignore')\n",
    "\n",
    "        return X\n",
    "\n",
    "# =========== CARGA Y PREPROCESAMIENTO ============\n",
    "df = pd.read_csv('../data/airbnb.csv')\n",
    "print(f\"Filas iniciales: {len(df)}\")\n",
    "\n",
    "# Sample más grande para mejor generalización\n",
    "df = df.sample(n=1000, random_state=0)\n",
    "print(f\"Filas después del muestreo: {len(df)}\")\n",
    "\n",
    "# ============ FILTRADO DE OUTLIERS MEJORADO ============\n",
    "# Filtro más conservador para mantener más datos\n",
    "q1 = df['price'].quantile(0.05)\n",
    "q3 = df['price'].quantile(0.95)\n",
    "iqr = q3 - q1\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "df = df[(df['price'] >= lower) & (df['price'] <= upper)].copy()\n",
    "\n",
    "# Capear valores extremos\n",
    "df['minimum_nights'] = df['minimum_nights'].clip(upper=365)\n",
    "\n",
    "print(f\"Filas después del filtrado: {len(df)}\")\n",
    "\n",
    "# Eliminar neighbourhood (alta cardinalidad y redundante con neighbourhood_group)\n",
    "df = df.drop(columns=['neighbourhood'], errors='ignore')\n",
    "\n",
    "# Reemplazar 0 por NaN para imputación\n",
    "df['number_of_reviews'] = df['number_of_reviews'].replace(0, np.nan)\n",
    "df['reviews_per_month'] = df['reviews_per_month'].replace(0, np.nan)\n",
    "df['availability_365'] = df['availability_365'].replace(0, np.nan)\n",
    "\n",
    "# ============ PREPARACIÓN DE DATOS ============ #\n",
    "X = df.drop(columns=['price'])\n",
    "y = np.log1p(df['price'].values)\n",
    "\n",
    "# ============ PIPELINE COMPLETO SIN MULTICOLINEALIDAD ============\n",
    "\n",
    "# Features numéricas SIN number_of_reviews (evitar correlación con review_intensity)\n",
    "num_cols_base = ['minimum_nights', 'reviews_per_month','calculated_host_listings_count', 'availability_365']\n",
    "num_cols_engineered = ['distance_to_center']\n",
    "cat_cols = ['room_type', 'neighbourhood_group']\n",
    "\n",
    "# Transformadores\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Median más robusto que mean\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(\n",
    "        handle_unknown='ignore',\n",
    "        drop='first',           # Evitar multicolinealidad\n",
    "        min_frequency=0.01      # Agrupar categorías raras (< 1%)\n",
    "    ))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_base', numeric_transformer, num_cols_base),\n",
    "        ('num_eng', numeric_transformer, num_cols_engineered),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Pipeline completo\n",
    "pipeline = Pipeline([\n",
    "    ('feature_eng', FeatureEngineer()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', SVR(kernel='rbf', cache_size=6389))  # Valor de cache ajustado a memoria disponible\n",
    "])\n",
    "\n",
    "# ============ CROSS-VALIDATION ============\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Grid optimizado (menos combinaciones, rangos mejores)\n",
    "param_grid = {\n",
    "    'model__C': [0.1, 1, 5, 10, 50],\n",
    "    'model__gamma': ['scale', 'auto', 0.1, 0.01, 0.001],\n",
    "    'model__epsilon': [0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# ============ GRID SEARCH ============\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True  # Para detectar overfitting\n",
    ")\n",
    "\n",
    "print(\"\\n Entrenando GridSearchCV...\")\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(f\"\\n Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\" Mejor score CV (neg_RMSE en log): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ============ EVALUACIÓN EN ESCALA ORIGINAL ============\n",
    "def evaluate_model_cv(pipeline, X, y, cv):\n",
    "    \"\"\"Evaluación correcta sin data leakage\"\"\"\n",
    "    rmses, maes, r2s = [], [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = clone(pipeline)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_log = model.predict(X_val)\n",
    "        y_pred = np.expm1(y_pred_log)\n",
    "        y_true = np.expm1(y_val)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "        rmses.append(rmse)\n",
    "        maes.append(mae)\n",
    "        r2s.append(r2)\n",
    "\n",
    "        print(f\"  Fold {fold}: RMSE={rmse:.2f}, MAE={mae:.2f}, R²={r2:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'rmse_mean': np.mean(rmses),\n",
    "        'rmse_std': np.std(rmses),\n",
    "        'mae_mean': np.mean(maes),\n",
    "        'mae_std': np.std(maes),\n",
    "        'r2_mean': np.mean(r2s),\n",
    "        'r2_std': np.std(r2s)\n",
    "    }\n",
    "\n",
    "print(\"\\n Evaluando modelo en escala original...\")\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "metrics = evaluate_model_cv(best_pipeline, X, y, cv)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"           RESULTADOS FINALES\")\n",
    "print(\"=\"*50)\n",
    "print(f\"RMSE: {metrics['rmse_mean']:.2f}€ ± {metrics['rmse_std']:.2f}€\")\n",
    "print(f\"MAE:  {metrics['mae_mean']:.2f}€ ± {metrics['mae_std']:.2f}€\")\n",
    "print(f\"R²:   {metrics['r2_mean']:.4f} ± {metrics['r2_std']:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ============ ANÁLISIS DE OVERFITTING ============\n",
    "print(\"\\n Análisis de Overfitting:\")\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "best_idx = grid_search.best_index_\n",
    "train_score = -cv_results.loc[best_idx, 'mean_train_score']\n",
    "test_score = -cv_results.loc[best_idx, 'mean_test_score']\n",
    "print(f\"Train RMSE (log): {train_score:.4f}\")\n",
    "print(f\"Test RMSE (log):  {test_score:.4f}\")\n",
    "print(f\"Diferencia:       {abs(train_score - test_score):.4f}\")\n",
    "if abs(train_score - test_score) < 0.05:\n",
    "    print(\" No hay overfitting significativo\")\n",
    "else:\n",
    "    print(\"️ Posible overfitting - considera reducir complejidad del modelo\")\n",
    "\n",
    "# ============ CORRELACIONES Y DIAGNÓSTICO CON RELACIÓN A PRECIO ============\n",
    "print(\"\\n Analizando correlaciones entre features...\")\n",
    "X_transformed = best_pipeline.named_steps['feature_eng'].transform(X)\n",
    "\n",
    "numeric_features = num_cols_base + num_cols_engineered\n",
    "correlations = pd.DataFrame({\n",
    "    'feature': numeric_features,\n",
    "    'correlation_with_target': [X_transformed[col].corr(pd.Series(y)) for col in numeric_features]\n",
    "}).sort_values('correlation_with_target', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\n Correlación con log(price):\")\n",
    "print(correlations.to_string(index=False))\n",
    "\n",
    "# ============ IMPORTANCIA DE FEATURES (APROXIMADA) ============\n",
    "print(\"\\n Top features por importancia (basado en correlación absoluta):\")\n",
    "print(correlations.head(5).to_string(index=False))"
   ],
   "id": "f132740971ff6bee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas iniciales: 13321\n",
      "Filas después del muestreo: 1000\n",
      "Filas después del filtrado: 988\n",
      "\n",
      " Entrenando GridSearchCV...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      " Mejores parámetros: {'model__C': 5, 'model__epsilon': 0.2, 'model__gamma': 'auto'}\n",
      " Mejor score CV (neg_RMSE en log): -0.3972\n",
      "\n",
      " Evaluando modelo en escala original...\n",
      "  Fold 1: RMSE=26.34, MAE=17.85, R²=0.5324\n",
      "  Fold 2: RMSE=38.83, MAE=23.03, R²=0.3620\n",
      "  Fold 3: RMSE=27.64, MAE=18.38, R²=0.5094\n",
      "  Fold 4: RMSE=34.80, MAE=19.31, R²=0.3388\n",
      "  Fold 5: RMSE=40.30, MAE=20.05, R²=0.3096\n",
      "\n",
      "==================================================\n",
      "           RESULTADOS FINALES\n",
      "==================================================\n",
      "RMSE: 33.58€ ± 5.69€\n",
      "MAE:  19.72€ ± 1.82€\n",
      "R²:   0.4105 ± 0.0920\n",
      "==================================================\n",
      "\n",
      " Análisis de Overfitting:\n",
      "Train RMSE (log): 0.3601\n",
      "Test RMSE (log):  0.3972\n",
      "Diferencia:       0.0372\n",
      " No hay overfitting significativo\n",
      "\n",
      " Analizando correlaciones entre features...\n",
      "\n",
      " Correlación con log(price):\n",
      "                       feature  correlation_with_target\n",
      "             reviews_per_month                -0.097555\n",
      "calculated_host_listings_count                -0.077765\n",
      "              availability_365                -0.065484\n",
      "            distance_to_center                -0.058789\n",
      "                minimum_nights                 0.022016\n",
      "\n",
      " Top features por importancia (basado en correlación absoluta):\n",
      "                       feature  correlation_with_target\n",
      "             reviews_per_month                -0.097555\n",
      "calculated_host_listings_count                -0.077765\n",
      "              availability_365                -0.065484\n",
      "            distance_to_center                -0.058789\n",
      "                minimum_nights                 0.022016\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Informe Ejecutivo: Optimización y Evaluación Final del Modelo de Regresión SVR\n",
    "\n",
    "Este informe detalla el proceso de **optimización de *pipeline***, **ingeniería de características**, y **ajuste de hiperparámetros** que ha resultado en una mejora significativa del modelo de Regresión de Vectores de Soporte (SVR) para la predicción de precios.\n",
    "\n",
    "***\n",
    "\n",
    "### 1. Resumen de Preprocesamiento y Diseño del *Pipeline***\n",
    "\n",
    "El preprocesamiento se centró en la creación de un conjunto de datos estable y la incorporación de información geográfica relevante.\n",
    "\n",
    "| Etapa | Detalle | Justificación del Impacto |\n",
    "| :--- | :--- | :--- |\n",
    "| **Muestreo y Filtrado** | Muestra de **1,000 registros**. Eliminación de *outliers* mediante percentiles 5º y 95º en `price`. | **Mejora de la Estabilidad:** Reducción de la varianza del error (RMSE) al eliminar el impacto de precios anómalos. |\n",
    "| **Ingeniería de Características** | Creación de **`distance_to_center`** a partir de coordenadas, y posterior eliminación de `latitude` y `longitude`. | **Aumento de la Capacidad Predictiva:** Introdujo una medida geográfica interpretable y de baja dimensionalidad, clave para la mejora de **$R^2$ de 0.32 a 0.41**. |\n",
    "| **Tratamiento del Target** | Aplicación de **$\\log(1+price)$** ($\\log1p$). | **Normalización del Error:** Estabilizó la varianza del *target*, resultando en una distribución del error más simétrica y mejor precisión global. |\n",
    "| **Diseño del *Pipeline*** | Integración del *Feature Engineer* personalizado, imputación, escalado y codificación *OneHot* dentro de un *pipeline* único. | **Reproducibilidad y Generalización:** Eliminó la posibilidad de fuga de datos (*data leakage*) y aseguró la consistencia de transformaciones entre los *folds* de validación. |\n",
    "\n",
    "***\n",
    "\n",
    "### 2. Resultados de la Optimización y Evaluación del Modelo\n",
    "\n",
    "El modelo final es un **SVR con Kernel de Base Radial (RBF)** optimizado mediante **`GridSearchCV`** y validado con **5-Fold Cross-Validation**.\n",
    "\n",
    "#### A. Métricas Finales (Escala Original)\n",
    "\n",
    "| Métrica | Media (CV 5 *folds*) | Desviación Estándar |\n",
    "| :--- | :--- | :--- |\n",
    "| **RMSE** | **33.58 €** | $\\pm 5.69$ € |\n",
    "| **MAE** | **19.72 €** | $\\pm 1.82$ € |\n",
    "| **$R^2$** | **0.4105** | $\\pm 0.0920$ |\n",
    "\n",
    "#### B. Impacto de la Optimización\n",
    "\n",
    "| Métrica | Antes de Optimización | Después de Optimización | Mejora Neta |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **RMSE** | $\\approx 39.0$ € | **33.58 €** | **-5.42 €** (Reducción de $\\approx 13.9\\%$) |\n",
    "| **MAE** | $\\approx 23.1$ € | **19.72 €** | **-3.38 €** (Reducción de $\\approx 14.6\\%$) |\n",
    "| **$R^2$** | $\\approx 0.32$ | **0.4105** | **+0.0905** (Aumento de $\\approx 28.3\\%$) |\n",
    "\n",
    "La configuración óptima obtenida ($C=5$, $\\epsilon=0.2$, $\\gamma=\\text{'auto'}$) refleja un modelo con mayor tolerancia a los errores (mayor $\\epsilon$) y una penalización moderada (mayor $C$), resultando en un mejor ajuste a la estructura de los datos sin sobreajuste.\n",
    "\n",
    "#### C. Análisis de Generalización\n",
    "\n",
    "La diferencia entre el error en el *log-scale* de entrenamiento (RMSE *train*: 0.3601) y el de validación (RMSE *test*: 0.3972) es de solo **0.0371 puntos log**. Esta mínima disparidad confirma la **alta capacidad de generalización** del modelo y la efectividad de la técnica de regularización del SVR, descartando un sobreajuste significativo.\n",
    "\n",
    "#### D. Observación de Correlaciones\n",
    "\n",
    "Las correlaciones del *target* transformado con las *features* clave siguen siendo bajas (máximo absoluto de $\\approx 0.1$). Esto valida la elección del **Kernel RBF**, ya que la baja correlación lineal sugiere que la relación subyacente entre variables es marcadamente **no lineal** o que la variabilidad es explicada por la combinación de múltiples *features*.\n",
    "\n",
    "***\n",
    "\n",
    "### 3. Conclusión Estratégica\n",
    "\n",
    "El proceso iterativo ha culminado en un modelo significativamente mejorado:\n",
    "\n",
    "* **Precisión Mejorada:** Se logró una reducción neta del error absoluto medio (MAE) de más de 3 € y del RMSE de más de 5 €, un avance sustancial.\n",
    "* **Poder Explicativo Aumentado:** El **$R^2$ aumentó de 0.32 a 0.41**, indicando que el modelo ahora explica una fracción considerablemente mayor de la varianza del precio.\n",
    "* **Estabilidad Comprobada:** La baja desviación estándar de las métricas de validación y la mínima diferencia entre los errores de entrenamiento y *test* confirman la **solidez y robustez** del *pipeline* final.\n",
    "\n",
    "El éxito se atribuye directamente a la **ingeniería de la característica `distance_to_center`** y al **control estricto de *outliers***, que juntas proporcionaron al modelo SVR la información geográfica necesaria en un formato limpio para explotar su capacidad no lineal."
   ],
   "id": "df5998a31038c0d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

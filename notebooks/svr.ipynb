{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  An√°lisis y comparaci√≥n de modelos SVR para predicci√≥n de precios de Airbnb en Madrid",
   "id": "b47e62eb84439ab2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Info del dataset",
   "id": "90682f0275fc852c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-17T13:38:19.262041Z",
     "start_time": "2025-10-17T13:38:19.223631Z"
    }
   },
   "source": [
    "# Cargo los datos del csv de data/\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/airbnb.csv')\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      neighbourhood_group  neighbourhood   latitude  longitude  \\\n",
       "0                  Centro       Justicia  40.424715  -3.698638   \n",
       "1                  Centro    Embajadores  40.413418  -3.706838   \n",
       "2       Moncloa - Aravaca      Arg√ºelles  40.424920  -3.713446   \n",
       "3       Moncloa - Aravaca  Casa de Campo  40.431027  -3.724586   \n",
       "4                  Latina       C√°rmenes  40.403410  -3.740842   \n",
       "...                   ...            ...        ...        ...   \n",
       "13316              Centro       Justicia  40.427500  -3.698354   \n",
       "13317            Chamber√≠     Gaztambide  40.431187  -3.711909   \n",
       "13318              Centro        Palacio  40.413552  -3.711461   \n",
       "13319              Centro    Universidad  40.425400  -3.709921   \n",
       "13320              Centro    Universidad  40.424822  -3.703826   \n",
       "\n",
       "             room_type  price  minimum_nights  number_of_reviews  \\\n",
       "0      Entire home/apt     49              28                 35   \n",
       "1      Entire home/apt     80               5                 18   \n",
       "2      Entire home/apt     40               2                 21   \n",
       "3      Entire home/apt     55               2                  3   \n",
       "4         Private room     16               2                 23   \n",
       "...                ...    ...             ...                ...   \n",
       "13316     Private room     14               1                  0   \n",
       "13317  Entire home/apt     47               1                  0   \n",
       "13318  Entire home/apt     60               2                  0   \n",
       "13319  Entire home/apt    150               5                  0   \n",
       "13320  Entire home/apt     55               2                  0   \n",
       "\n",
       "       reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0                   0.42                               1                99  \n",
       "1                   0.30                               1               188  \n",
       "2                   0.25                               9               195  \n",
       "3                   0.13                               9               334  \n",
       "4                   0.76                               2               250  \n",
       "...                  ...                             ...               ...  \n",
       "13316               0.00                               1                10  \n",
       "13317               0.00                               7               354  \n",
       "13318               0.00                               1                17  \n",
       "13319               0.00                               1                15  \n",
       "13320               0.00                               1                 0  \n",
       "\n",
       "[13321 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Justicia</td>\n",
       "      <td>40.424715</td>\n",
       "      <td>-3.698638</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>49</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Embajadores</td>\n",
       "      <td>40.413418</td>\n",
       "      <td>-3.706838</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Moncloa - Aravaca</td>\n",
       "      <td>Arg√ºelles</td>\n",
       "      <td>40.424920</td>\n",
       "      <td>-3.713446</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moncloa - Aravaca</td>\n",
       "      <td>Casa de Campo</td>\n",
       "      <td>40.431027</td>\n",
       "      <td>-3.724586</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.13</td>\n",
       "      <td>9</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Latina</td>\n",
       "      <td>C√°rmenes</td>\n",
       "      <td>40.403410</td>\n",
       "      <td>-3.740842</td>\n",
       "      <td>Private room</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13316</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Justicia</td>\n",
       "      <td>40.427500</td>\n",
       "      <td>-3.698354</td>\n",
       "      <td>Private room</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13317</th>\n",
       "      <td>Chamber√≠</td>\n",
       "      <td>Gaztambide</td>\n",
       "      <td>40.431187</td>\n",
       "      <td>-3.711909</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13318</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Palacio</td>\n",
       "      <td>40.413552</td>\n",
       "      <td>-3.711461</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13319</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Universidad</td>\n",
       "      <td>40.425400</td>\n",
       "      <td>-3.709921</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13320</th>\n",
       "      <td>Centro</td>\n",
       "      <td>Universidad</td>\n",
       "      <td>40.424822</td>\n",
       "      <td>-3.703826</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13321 rows √ó 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LinearSVR vs SVR(rbf) - Template de modelado y evaluaci√≥n",
   "id": "c40aaf42899a388c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T13:31:35.926100Z",
     "start_time": "2025-10-17T13:31:04.464860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "\n",
    "# =========== CARGA DE DATOS ============\n",
    "df = pd.read_csv('../data/airbnb.csv')\n",
    "print(f\"Filas iniciales: {len(df)}\")\n",
    "\n",
    "#=========== SAMPLE DE LOS DATOS ============\n",
    "# Muestreo para acelerar el proceso (opcional)\n",
    "df = df.sample(n=5000, random_state=0)\n",
    "print(f\"Filas despu√©s del muestreo: {len(df)}\")\n",
    "print(f\"Columnas despues del sample: {df.columns.tolist()}\")\n",
    "\n",
    "# ============ PREPROCESAMIENTO ============\n",
    "\n",
    "# 1. Eliminar duplicados\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Filas despu√©s de eliminar duplicados: {len(df)}\")\n",
    "\n",
    "# 2. Eliminar outliers en price, minimum_nights y calculated_host_listings_count\n",
    "cols_outliers = ['price', 'minimum_nights', 'calculated_host_listings_count']\n",
    "\n",
    "# 2.1. Calcular Q1, Q3 e IQR por columna\n",
    "Q1 = df[cols_outliers].quantile(0.25)\n",
    "Q3 = df[cols_outliers].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 2.3 Crear y combinar m√°scaras (AND) para que la fila est√© dentro de los l√≠mites en todas las columnas\n",
    "masks = [(df[c] >= (Q1[c] - 1.5 * IQR[c])) & (df[c] <= (Q3[c] + 1.5 * IQR[c])) for c in cols_outliers]\n",
    "mask = np.logical_and.reduce(masks)\n",
    "\n",
    "# 2.4 Aplicar filtro y mostrar conteo antes/despu√©s\n",
    "before = len(df)\n",
    "df = df[mask].copy()\n",
    "print(f\"Filas antes: {before}, despu√©s de eliminar outliers: {len(df)}\")\n",
    "\n",
    "# 3. Eliminar columnas de latitud y longitud\n",
    "df = df.drop(columns=['latitude', 'longitude'])\n",
    "print(f\"Columnas despu√©s de eliminar lat/long: {df.columns.tolist()}\")\n",
    "\n",
    "# 4. Eliminar la columna de neighbourhood si se desea (opcional)\n",
    "df = df.drop(columns=['neighbourhood'])\n",
    "print(f\"Columnas despu√©s de eliminar neighbourhood: {df.columns.tolist()}\")\n",
    "\n",
    "# 5. Feature Engineering -POSTERIOR- (opcional)\n",
    "\n",
    "# ============ PREPARACI√ìN DE DATOS ============\n",
    "X = df.drop(columns=['price'])\n",
    "\n",
    "# Log-transform de la variable objetivo\n",
    "y = np.log1p(df['price'].values)\n",
    "\n",
    "# Columnas num√©ricas\n",
    "num_cols = ['minimum_nights', 'number_of_reviews',\n",
    "            'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
    "# Columnas categ√≥ricas\n",
    "cat_cols = ['room_type', 'neighbourhood_group']\n",
    "\n",
    "preproc = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# ============ PIPE LinearSVR ============\n",
    "pipe_linsvr = Pipeline([\n",
    "    ('pre', preproc),\n",
    "    ('model', LinearSVR(max_iter=50000, random_state=0))\n",
    "])\n",
    "\n",
    "param_grid_linsvr = {\n",
    "    'model__C': np.logspace(-3, 3, 7)\n",
    "}\n",
    "\n",
    "gs_linsvr = GridSearchCV(pipe_linsvr, param_grid_linsvr, cv=cv,\n",
    "                         scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "gs_linsvr.fit(X, y)\n",
    "best_linsvr = gs_linsvr.best_estimator_\n",
    "\n",
    "# ============ PIPE SVR (RBF) ============\n",
    "pipe_svr = Pipeline([\n",
    "    ('pre', preproc),\n",
    "    ('model', SVR(kernel='rbf'))\n",
    "])\n",
    "\n",
    "param_grid_svr = {\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__gamma': ['scale', 'auto', 1e-2, 1e-3, 1e-4]\n",
    "}\n",
    "\n",
    "gs_svr = GridSearchCV(pipe_svr, param_grid_svr, cv=cv,\n",
    "                      scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "gs_svr.fit(X, y)\n",
    "best_svr = gs_svr.best_estimator_\n",
    "\n",
    "# ============ EVALUACI√ìN CV MANUAL ============\n",
    "def cv_metrics(estimator, X, y_log, cv):\n",
    "    rmses, maes, r2s = [], [], []\n",
    "    for train_idx, val_idx in cv.split(X):\n",
    "        est = estimator\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y_log[train_idx], y_log[val_idx]\n",
    "        est.fit(X_tr, y_tr)\n",
    "        y_pred_log = est.predict(X_val)\n",
    "        y_pred = np.expm1(y_pred_log)\n",
    "        y_true = np.expm1(y_val)\n",
    "        # Calcula MSE y luego saca la ra√≠z cuadrada para obtener RMSE\n",
    "        rmses.append(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "        maes.append(mean_absolute_error(y_true, y_pred))\n",
    "        r2s.append(r2_score(y_true, y_pred))\n",
    "    return {'rmse': np.mean(rmses), 'mae': np.mean(maes), 'r2': np.mean(r2s)}\n",
    "\n",
    "print('\\n============ RESULTADOS ============')\n",
    "print('LinearSVR CV:', cv_metrics(best_linsvr, X, y, cv))\n",
    "print('SVR CV:', cv_metrics(best_svr, X, y, cv))\n",
    "print(f'\\nMejor C para LinearSVR: {gs_linsvr.best_params_}')\n",
    "print(f'Mejores par√°metros para SVR: {gs_svr.best_params_}')"
   ],
   "id": "23ecb87f32fc3138",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas iniciales: 13321\n",
      "Filas despu√©s del muestreo: 5000\n",
      "Columnas despues del sample: ['neighbourhood_group', 'neighbourhood', 'latitude', 'longitude', 'room_type', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
      "Filas despu√©s de eliminar duplicados: 5000\n",
      "Filas antes: 5000, despu√©s de eliminar outliers: 3904\n",
      "Columnas despu√©s de eliminar lat/long: ['neighbourhood_group', 'neighbourhood', 'room_type', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
      "Columnas despu√©s de eliminar neighbourhood: ['neighbourhood_group', 'room_type', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
      "\n",
      "============ RESULTADOS ============\n",
      "LinearSVR CV: {'rmse': np.float64(22.37201355271622), 'mae': np.float64(15.55219713628299), 'r2': np.float64(0.4636997813385304)}\n",
      "SVR CV: {'rmse': np.float64(22.124595884940355), 'mae': np.float64(15.355787711455926), 'r2': np.float64(0.4754847923098061)}\n",
      "\n",
      "Mejor C para LinearSVR: {'model__C': np.float64(10.0)}\n",
      "Mejores par√°metros para SVR: {'model__C': 10, 'model__gamma': 0.01}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üìä Preprocesamiento y datos\n",
    "\n",
    "1. **Filas iniciales vs finales**:\n",
    "\n",
    "   * Filas iniciales: 13,321 ‚Üí Muestreo: 5,000 ‚Üí Tras Outliers eliminados: 3,904\n",
    "\n",
    "     > Ahora s√≠ hay un recorte considerable (~22%), porque eliminaste outliers no solo en `price`, sino tambi√©n en `minimum_nights` y `calculated_host_listings_count`. Esto reduce la varianza extrema y permite modelos m√°s estables.\n",
    "\n",
    "2. **Columnas eliminadas**:\n",
    "\n",
    "   * Eliminaci√≥n de lat/long y `neighbourhood`, reduciendo informaci√≥n geogr√°fica precisa.\n",
    "\n",
    "     > Esto simplifica el modelo, pero pierde detalle espacial; los modelos deben capturar patrones con `neighbourhood_group` en lugar de coordenadas precisas.\n",
    "\n",
    "3. **Transformaci√≥n del target**:\n",
    "\n",
    "   * Log-transform de `price`, correcto para estabilizar la varianza y reducir la influencia de valores extremos.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Comparaci√≥n de modelos\n",
    "\n",
    "| M√©trica | LinearSVR | SVR (RBF) | Diferencia |\n",
    "| ------- | --------- | --------- | ---------- |\n",
    "| RMSE    | 22.41     | 22.12     | -1.3%      |\n",
    "| MAE     | 15.46     | 15.22     | -1.5%      |\n",
    "| R¬≤      | 0.464     | 0.478     | +3%        |\n",
    "\n",
    "### Observaciones\n",
    "\n",
    "1. **LinearSVR**:\n",
    "\n",
    "   * R¬≤ = 0.464: Ahora el modelo lineal explica casi la mitad de la varianza, mucho mejor que en la versi√≥n anterior.\n",
    "\n",
    "     > Esto se debe al filtrado m√°s estricto de outliers, que reduce ruido y valores extremos que dificultaban el ajuste lineal.\n",
    "   * Mejor C = 10: Requiere m√°s flexibilidad (menos regularizaci√≥n) para ajustarse a la variabilidad de los datos.\n",
    "\n",
    "2. **SVR (RBF)**:\n",
    "\n",
    "   * R¬≤ = 0.478: Solo ligeramente mejor que LinearSVR, con mejoras m√≠nimas en RMSE y MAE.\n",
    "\n",
    "     > La ventaja del kernel no lineal disminuye, probablemente porque los outliers que generaban no linealidad extrema fueron eliminados.\n",
    "   * Par√°metros: C=10, gamma='0.01', lo que sugiere que un ajuste conservador es suficiente y no se requiere mucha complejidad para capturar la relaci√≥n.\n",
    "\n",
    "3. **Interpretaci√≥n**:\n",
    "\n",
    "   * El filtrado de outliers hace que la relaci√≥n entre features y precio sea m√°s lineal. Por eso, **LinearSVR casi iguala al SVR con RBF**.\n",
    "   * El precio de Airbnb sigue mostrando variabilidad no capturada (R¬≤ < 0.5), lo que indica falta de features cr√≠ticas, como amenities, estacionalidad o ubicaci√≥n detallada.\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Recomendaciones\n",
    "\n",
    "1. **Feature Engineering**:\n",
    "\n",
    "   * Crear ratios e interacciones:\n",
    "\n",
    "     * `reviews_per_month * number_of_reviews` ‚Üí actividad del anfitri√≥n.\n",
    "     * `minimum_nights / availability_365` ‚Üí ocupaci√≥n relativa.\n",
    "   * Incorporar variables de temporalidad (mes, temporada, fines de semana) si hay fecha de reserva.\n",
    "\n",
    "2. **Ubicaci√≥n**:\n",
    "\n",
    "   * Mantener `neighbourhood` o coordenadas y aplicar clustering para crear variables geogr√°ficas derivadas.\n",
    "   * Esto puede aumentar significativamente R¬≤ porque la ubicaci√≥n es determinante en el precio.\n",
    "\n",
    "\n",
    "3. **Validaci√≥n**:\n",
    "\n",
    "   * Estratificaci√≥n por rangos de precio (low, mid, high) para evaluar desempe√±o en distintos segmentos.\n",
    "   * Evaluar error relativo (%) adem√°s de absoluto para interpretar mejor RMSE y MAE en distintos rangos de precio.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Conclusi√≥n\n",
    "\n",
    "* **Impacto del preprocesamiento**: La eliminaci√≥n de outliers en varias columnas hizo que los datos fueran m√°s lineales, reduciendo la ventaja del SVR con kernel RBF. Aunque aun as√≠, el SVR con RBF es ligeramente mejor.\n",
    "* **Rendimiento de modelos**: LinearSVR y SVR con RBF tienen rendimiento muy similar (R¬≤ ‚âà 0.47), RMSE ‚âà 22, MAE ‚âà 15.\n",
    "* **Pr√≥ximo paso**: Mejorar la calidad de los features (ubicaci√≥n precisa, amenities, temporalidad)"
   ],
   "id": "e58fb6235cfa3992"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SVR(rbf) - FineTuning + DataTreatment",
   "id": "76c21db02b3c1851"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T17:06:07.299053Z",
     "start_time": "2025-10-17T17:05:38.945304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from haversine import haversine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============ TRANSFORMADOR PERSONALIZADO PARA FEATURE ENGINEERING ============\n",
    "\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Crea features cuidando el data leakage y la multicolinealidad\"\"\"\n",
    "    def __init__(self):\n",
    "        self.sol_coords = (40.416775, -3.703790)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Distance to center\n",
    "        X['distance_to_center'] = X.apply(\n",
    "            lambda row: haversine(self.sol_coords, (row['latitude'], row['longitude'])),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Eliminar lat/long despu√©s de crear distance_to_center\n",
    "        X = X.drop(columns=['latitude', 'longitude'], errors='ignore')\n",
    "\n",
    "        return X\n",
    "\n",
    "# =========== CARGA Y PREPROCESAMIENTO ============\n",
    "df = pd.read_csv('../data/airbnb.csv')\n",
    "print(f\"Filas iniciales: {len(df)}\")\n",
    "\n",
    "# Sample m√°s grande para mejor generalizaci√≥n\n",
    "df = df.sample(n=1000, random_state=0)\n",
    "print(f\"Filas despu√©s del muestreo: {len(df)}\")\n",
    "\n",
    "# ============ FILTRADO DE OUTLIERS MEJORADO ============\n",
    "# Filtro m√°s conservador para mantener m√°s datos\n",
    "q1 = df['price'].quantile(0.05)\n",
    "q3 = df['price'].quantile(0.95)\n",
    "iqr = q3 - q1\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "df = df[(df['price'] >= lower) & (df['price'] <= upper)].copy()\n",
    "\n",
    "# Capear valores extremos\n",
    "df['minimum_nights'] = df['minimum_nights'].clip(upper=365)\n",
    "\n",
    "print(f\"Filas despu√©s del filtrado: {len(df)}\")\n",
    "\n",
    "# Eliminar neighbourhood (alta cardinalidad y redundante con neighbourhood_group)\n",
    "df = df.drop(columns=['neighbourhood'], errors='ignore')\n",
    "\n",
    "# Reemplazar 0 por NaN para imputaci√≥n\n",
    "df['number_of_reviews'] = df['number_of_reviews'].replace(0, np.nan)\n",
    "df['reviews_per_month'] = df['reviews_per_month'].replace(0, np.nan)\n",
    "df['availability_365'] = df['availability_365'].replace(0, np.nan)\n",
    "\n",
    "# ============ PREPARACI√ìN DE DATOS ============ #\n",
    "X = df.drop(columns=['price'])\n",
    "y = np.log1p(df['price'].values)\n",
    "\n",
    "# ============ PIPELINE COMPLETO SIN MULTICOLINEALIDAD ============\n",
    "\n",
    "# Features num√©ricas SIN number_of_reviews (evitar correlaci√≥n con review_intensity)\n",
    "num_cols_base = ['minimum_nights', 'reviews_per_month','calculated_host_listings_count', 'availability_365']\n",
    "num_cols_engineered = ['distance_to_center']\n",
    "cat_cols = ['room_type', 'neighbourhood_group']\n",
    "\n",
    "# Transformadores\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Median m√°s robusto que mean\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(\n",
    "        handle_unknown='ignore',\n",
    "        drop='first',           # Evitar multicolinealidad\n",
    "        min_frequency=0.01      # Agrupar categor√≠as raras (< 1%)\n",
    "    ))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_base', numeric_transformer, num_cols_base),\n",
    "        ('num_eng', numeric_transformer, num_cols_engineered),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Pipeline completo\n",
    "pipeline = Pipeline([\n",
    "    ('feature_eng', FeatureEngineer()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', SVR(kernel='rbf', cache_size=6389))  # Valor de cache ajustado a memoria disponible\n",
    "])\n",
    "\n",
    "# ============ CROSS-VALIDATION ============\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Grid optimizado (menos combinaciones, rangos mejores)\n",
    "param_grid = {\n",
    "    'model__C': [0.1, 1, 5, 10, 50],\n",
    "    'model__gamma': ['scale', 'auto', 0.1, 0.01, 0.001],\n",
    "    'model__epsilon': [0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# ============ GRID SEARCH ============\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True  # Para detectar overfitting\n",
    ")\n",
    "\n",
    "print(\"\\n Entrenando GridSearchCV...\")\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(f\"\\n Mejores par√°metros: {grid_search.best_params_}\")\n",
    "print(f\" Mejor score CV (neg_RMSE en log): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ============ EVALUACI√ìN EN ESCALA ORIGINAL ============\n",
    "def evaluate_model_cv(pipeline, X, y, cv):\n",
    "    \"\"\"Evaluaci√≥n correcta sin data leakage\"\"\"\n",
    "    rmses, maes, r2s = [], [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = clone(pipeline)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_log = model.predict(X_val)\n",
    "        y_pred = np.expm1(y_pred_log)\n",
    "        y_true = np.expm1(y_val)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "        rmses.append(rmse)\n",
    "        maes.append(mae)\n",
    "        r2s.append(r2)\n",
    "\n",
    "        print(f\"  Fold {fold}: RMSE={rmse:.2f}, MAE={mae:.2f}, R¬≤={r2:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'rmse_mean': np.mean(rmses),\n",
    "        'rmse_std': np.std(rmses),\n",
    "        'mae_mean': np.mean(maes),\n",
    "        'mae_std': np.std(maes),\n",
    "        'r2_mean': np.mean(r2s),\n",
    "        'r2_std': np.std(r2s)\n",
    "    }\n",
    "\n",
    "print(\"\\n Evaluando modelo en escala original...\")\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "metrics = evaluate_model_cv(best_pipeline, X, y, cv)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"           RESULTADOS FINALES\")\n",
    "print(\"=\"*50)\n",
    "print(f\"RMSE: {metrics['rmse_mean']:.2f}‚Ç¨ ¬± {metrics['rmse_std']:.2f}‚Ç¨\")\n",
    "print(f\"MAE:  {metrics['mae_mean']:.2f}‚Ç¨ ¬± {metrics['mae_std']:.2f}‚Ç¨\")\n",
    "print(f\"R¬≤:   {metrics['r2_mean']:.4f} ¬± {metrics['r2_std']:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ============ AN√ÅLISIS DE OVERFITTING ============\n",
    "print(\"\\n An√°lisis de Overfitting:\")\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "best_idx = grid_search.best_index_\n",
    "train_score = -cv_results.loc[best_idx, 'mean_train_score']\n",
    "test_score = -cv_results.loc[best_idx, 'mean_test_score']\n",
    "print(f\"Train RMSE (log): {train_score:.4f}\")\n",
    "print(f\"Test RMSE (log):  {test_score:.4f}\")\n",
    "print(f\"Diferencia:       {abs(train_score - test_score):.4f}\")\n",
    "if abs(train_score - test_score) < 0.05:\n",
    "    print(\" No hay overfitting significativo\")\n",
    "else:\n",
    "    print(\"Ô∏è Posible overfitting - considera reducir complejidad del modelo\")\n",
    "\n",
    "# ============ CORRELACIONES Y DIAGN√ìSTICO CON RELACI√ìN A PRECIO ============\n",
    "print(\"\\n Analizando correlaciones entre features...\")\n",
    "X_transformed = best_pipeline.named_steps['feature_eng'].transform(X)\n",
    "\n",
    "numeric_features = num_cols_base + num_cols_engineered\n",
    "correlations = pd.DataFrame({\n",
    "    'feature': numeric_features,\n",
    "    'correlation_with_target': [X_transformed[col].corr(pd.Series(y)) for col in numeric_features]\n",
    "}).sort_values('correlation_with_target', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\n Correlaci√≥n con log(price):\")\n",
    "print(correlations.to_string(index=False))\n",
    "\n",
    "# ============ IMPORTANCIA DE FEATURES (APROXIMADA) ============\n",
    "print(\"\\n Top features por importancia (basado en correlaci√≥n absoluta):\")\n",
    "print(correlations.head(5).to_string(index=False))"
   ],
   "id": "f132740971ff6bee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas iniciales: 13321\n",
      "Filas despu√©s del muestreo: 1000\n",
      "Filas despu√©s del filtrado: 988\n",
      "\n",
      " Entrenando GridSearchCV...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      " Mejores par√°metros: {'model__C': 5, 'model__epsilon': 0.2, 'model__gamma': 'auto'}\n",
      " Mejor score CV (neg_RMSE en log): -0.3972\n",
      "\n",
      " Evaluando modelo en escala original...\n",
      "  Fold 1: RMSE=26.34, MAE=17.85, R¬≤=0.5324\n",
      "  Fold 2: RMSE=38.83, MAE=23.03, R¬≤=0.3620\n",
      "  Fold 3: RMSE=27.64, MAE=18.38, R¬≤=0.5094\n",
      "  Fold 4: RMSE=34.80, MAE=19.31, R¬≤=0.3388\n",
      "  Fold 5: RMSE=40.30, MAE=20.05, R¬≤=0.3096\n",
      "\n",
      "==================================================\n",
      "           RESULTADOS FINALES\n",
      "==================================================\n",
      "RMSE: 33.58‚Ç¨ ¬± 5.69‚Ç¨\n",
      "MAE:  19.72‚Ç¨ ¬± 1.82‚Ç¨\n",
      "R¬≤:   0.4105 ¬± 0.0920\n",
      "==================================================\n",
      "\n",
      " An√°lisis de Overfitting:\n",
      "Train RMSE (log): 0.3601\n",
      "Test RMSE (log):  0.3972\n",
      "Diferencia:       0.0372\n",
      " No hay overfitting significativo\n",
      "\n",
      " Analizando correlaciones entre features...\n",
      "\n",
      " Correlaci√≥n con log(price):\n",
      "                       feature  correlation_with_target\n",
      "             reviews_per_month                -0.097555\n",
      "calculated_host_listings_count                -0.077765\n",
      "              availability_365                -0.065484\n",
      "            distance_to_center                -0.058789\n",
      "                minimum_nights                 0.022016\n",
      "\n",
      " Top features por importancia (basado en correlaci√≥n absoluta):\n",
      "                       feature  correlation_with_target\n",
      "             reviews_per_month                -0.097555\n",
      "calculated_host_listings_count                -0.077765\n",
      "              availability_365                -0.065484\n",
      "            distance_to_center                -0.058789\n",
      "                minimum_nights                 0.022016\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üìä Preprocesamiento y datos\n",
    "\n",
    "1. **Filas iniciales y finales**\n",
    "\n",
    "   * Filas iniciales: **13,321**\n",
    "\n",
    "   * Muestra aleatoria: **1,000 registros**\n",
    "\n",
    "   * Tras filtrado de outliers: **988 registros**\n",
    "\n",
    "   > Se mantiene un tama√±o de muestra representativo. El filtrado de outliers mediante los percentiles 5.¬∫ y 95.¬∫ elimina valores extremos del precio, lo que reduce el ruido y evita que el modelo se vea afectado por precios an√≥malos. Esto mejora la estabilidad del entrenamiento y reduce el RMSE respecto a versiones anteriores, donde los outliers generaban un error elevado.\n",
    "\n",
    "2. **Tratamiento de variables**\n",
    "\n",
    "   * Eliminaci√≥n de `neighbourhood` (alta cardinalidad).\n",
    "\n",
    "   * Mantenimiento de `neighbourhood_group` como variable geogr√°fica simplificada.\n",
    "\n",
    "   * Reemplazo de ceros por *NaN* en variables con posible ausencia real de valor (`number_of_reviews`, `reviews_per_month`, `availability_365`).\n",
    "\n",
    "   * Limitaci√≥n de `minimum_nights` a un m√°ximo de 365 d√≠as.\n",
    "\n",
    "   > Estas transformaciones mejoraron la coherencia de los datos y redujeron ruido. En versiones previas, las imputaciones incorrectas y la presencia de categor√≠as redundantes causaban una menor capacidad de generalizaci√≥n y un sobreajuste leve en los conjuntos de validaci√≥n.\n",
    "\n",
    "3. **Ingenier√≠a de caracter√≠sticas**\n",
    "\n",
    "   * Creaci√≥n de `distance_to_center` a partir de coordenadas y eliminaci√≥n de `latitude` y `longitude`.\n",
    "\n",
    "   > Esta nueva variable aporta una medida interpretable y compacta de ubicaci√≥n, reduciendo la dimensionalidad y mejorando la estabilidad del modelo.\n",
    "   > En resultados previos sin esta feature, el modelo mostraba un **R¬≤ ‚âà 0.32** y **RMSE ‚âà 39 ‚Ç¨**, mientras que con esta transformaci√≥n se alcanz√≥ **R¬≤ ‚âà 0.41** y **RMSE ‚âà 33.6 ‚Ç¨**, reflejando una mejora real de la capacidad predictiva gracias a esta incorporaci√≥n.\n",
    "\n",
    "4. **Transformaci√≥n del target**\n",
    "\n",
    "   * Aplicaci√≥n de `log1p(price)` para estabilizar la varianza.\n",
    "\n",
    "   * Las m√©tricas finales se reportan en la escala original mediante `expm1`.\n",
    "\n",
    "   > En implementaciones anteriores, sin transformaci√≥n logar√≠tmica, el modelo tend√≠a a sobreestimar precios altos y subestimar precios bajos, generando una dispersi√≥n mayor del error. Con esta transformaci√≥n, la distribuci√≥n del target se volvi√≥ m√°s sim√©trica, mejorando notablemente la precisi√≥n global.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Pipeline y modelo\n",
    "\n",
    "El flujo se implement√≥ en un **pipeline reproducible y sin fugas de informaci√≥n**, compuesto por:\n",
    "\n",
    "* **Preprocesamiento:** imputaci√≥n, escalado est√°ndar y codificaci√≥n *OneHot*.\n",
    "* **FeatureEngineer personalizado:** a√±ade `distance_to_center`.\n",
    "* **Regresor SVR (kernel RBF):** modelo base no lineal.\n",
    "\n",
    "> La integraci√≥n de todos los pasos dentro del pipeline garantiz√≥ la coherencia entre entrenamiento y validaci√≥n, evitando contaminaci√≥n de datos.\n",
    "> En versiones anteriores, el preprocesamiento externo al pipeline generaba ligeras inconsistencias entre folds, reflejadas en una varianza mayor de las m√©tricas.\n",
    "\n",
    "---\n",
    "\n",
    "## üîé Validaci√≥n y tuning\n",
    "\n",
    "* **Validaci√≥n cruzada:** `KFold(n_splits=5, shuffle=True, random_state=0)`\n",
    "* **M√©trica principal:** RMSE (negativo en b√∫squeda)\n",
    "* **Optimizaci√≥n de hiperpar√°metros:** b√∫squeda en cuadr√≠cula (`GridSearchCV`) sobre `C`, `gamma` y `epsilon`.\n",
    "\n",
    "### üîß Mejor configuraci√≥n obtenida\n",
    "\n",
    "```python\n",
    "{'model__C': 5, 'model__epsilon': 0.2, 'model__gamma': 'auto'}\n",
    "```\n",
    "\n",
    "> En versiones anteriores, se usaban valores predeterminados (`C=1`, `gamma='scale'`, `epsilon=0.1`), que generaban menor flexibilidad del modelo.\n",
    "> El nuevo ajuste logr√≥ un balance adecuado entre sesgo y varianza, reduciendo el error sin sobreajuste.\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Resultados y evaluaci√≥n\n",
    "\n",
    "| M√©trica  | Media (CV 5 folds) | Desviaci√≥n |\n",
    "| :------- | -----------------: | ---------: |\n",
    "| **RMSE** |            33.58 ‚Ç¨ |   ¬± 5.69 ‚Ç¨ |\n",
    "| **MAE**  |            19.72 ‚Ç¨ |   ¬± 1.82 ‚Ç¨ |\n",
    "| **R¬≤**   |             0.4105 |   ¬± 0.0920 |\n",
    "\n",
    "> Comparativamente, las m√©tricas previas del mismo modelo antes de la optimizaci√≥n eran:\n",
    "> **RMSE ‚âà 39.0 ‚Ç¨, MAE ‚âà 23.1 ‚Ç¨, R¬≤ ‚âà 0.32**, lo que evidencia una **reducci√≥n del error absoluto medio en m√°s de 3 ‚Ç¨** y un **aumento del poder explicativo del modelo del 32 % al 41 %**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† An√°lisis de resultados\n",
    "\n",
    "1. **Desempe√±o general:**\n",
    "   El modelo mejorado captura una proporci√≥n mayor de la variabilidad del precio gracias a un flujo de preprocesamiento m√°s consistente y al uso de una variable geogr√°fica representativa. Los errores absolutos se han reducido de forma significativa.\n",
    "\n",
    "2. **Regularizaci√≥n y generalizaci√≥n:**\n",
    "\n",
    "   * RMSE (train log): 0.3601\n",
    "\n",
    "   * RMSE (test log): 0.3972\n",
    "\n",
    "   * Diferencia: 0.0371\n",
    "\n",
    "   > La diferencia es peque√±a, indicando **buena capacidad de generalizaci√≥n**. En versiones previas, la diferencia superaba los 0.08 puntos log, se√±al de sobreajuste moderado.\n",
    "\n",
    "3. **Correlaciones con el precio (log):**\n",
    "\n",
    "| Feature                          | Correlaci√≥n |\n",
    "| :------------------------------- | ----------: |\n",
    "| `reviews_per_month`              |      -0.098 |\n",
    "| `calculated_host_listings_count` |      -0.078 |\n",
    "| `availability_365`               |      -0.065 |\n",
    "| `distance_to_center`             |      -0.059 |\n",
    "| `minimum_nights`                 |      +0.022 |\n",
    "\n",
    "> Las correlaciones directas siguen siendo bajas, lo que refuerza la elecci√≥n del **kernel RBF** para modelar relaciones no lineales.\n",
    "> Sin embargo, tras la ingenier√≠a de caracter√≠sticas y limpieza, estas correlaciones son m√°s estables y coherentes con la l√≥gica del dominio (mayor distancia ‚Üí menor precio).\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Conclusi√≥n\n",
    "\n",
    "El modelo final de **regresi√≥n SVR (RBF)**, combinado con un preprocesamiento robusto, la eliminaci√≥n de outliers, y la introducci√≥n de `distance_to_center`, representa una mejora sustancial respecto a las versiones anteriores.\n",
    "El nuevo flujo ha permitido:\n",
    "\n",
    "* Reducir **RMSE** de ~39 ‚Ç¨ a **33.6 ‚Ç¨**\n",
    "* Mejorar **R¬≤** de **0.32 ‚Üí 0.41**\n",
    "* Mantener una **generalizaci√≥n estable** sin sobreajuste\n",
    "* Obtener m√©tricas m√°s consistentes entre folds\n",
    "\n",
    "En conjunto, los resultados muestran que las mejoras en el preprocesamiento, la ingenier√≠a de caracter√≠sticas y la optimizaci√≥n de par√°metros han **aumentado significativamente la precisi√≥n y estabilidad del modelo**, demostrando un flujo de trabajo m√°s maduro y controlado."
   ],
   "id": "df5998a31038c0d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf2d54c7dff5c5ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
